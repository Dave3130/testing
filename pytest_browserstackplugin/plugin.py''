import atexit
import datetime
import inspect
import logging
import signal
import threading
from uuid import uuid4
from bstack_utils.measure import performance_tester
from bstack_utils.percy_sdk import PercySDK

import pytest
from packaging import version

from browserstack_sdk.__init__ import (get_caps, sanitize_config, update, create_options_from_caps,
                                       mod_pytest_report_header, mod_pytest_bstack_makereport, mod_start, mod_stop,
                                       update_options, import_error_handler, set_config_for_process,
                                       set_browser_proxy, getAccessibilityResults, getAccessibilityResultsSummary, perform_scan, is_browserstack_executor_script)
from browserstack_sdk.pytest_handler import PytestHandler
from browserstack_sdk._version import __version__
from bstack_utils import logger_utils
from bstack_utils.capture import CaptureLogs
from bstack_utils.config import Config
from bstack_utils.percy import *
from bstack_utils.constants import DEFAULT_LOG_LEVEL, MIN_PROXY_SUPPORTED_VERSION, LOCAL_NUDGE_ERROR_CODES, \
    PYTEST_PYTHON
from bstack_utils.helper import get_thread_value_or_default, get_utcfromtimestamp_wo_tzinfo, get_utcnow_wo_tzinfo, is_selenium_installed, is_bstack_automation, current_time, \
    get_outcome_status, \
    get_tags_from_markers, selenium_version_used, get_hub_url, is_browserstack_session, is_pytest_bdd, Notset, \
    is_w3c_mode, time_diff, get_backtrace_from_exception, Result, iso_from_timestamp, empty_log, error_handler, \
    set_optimal_hub_urls, store_pytest_error_list, is_true, is_windows
from bstack_utils.hooks_patch import HooksPatch
from bstack_utils.messages import NEW_HUB_URL_ERROR, NEW_HUB_URL, SETUP_COMPLETE, REMOTE_HUB, IMPORT_ERROR_PYTEST, \
    PROXY_SETUP_ERROR, PROXY_NOT_SUPPORTED, CONFIG_FILE_CONTENT, NUDGE_LOCAL_FUNC_EXCEPTION_ERROR, SESSION_STARTED_ID, \
    IMPORT_ERROR_SEL_PW, SETUP_START, START_SESSION_FAILURE
from bstack_utils.proxy import get_proxy_if_exists, read_proxy_from_pac
from bstack_utils.pytest_utils import mod_pytest_selenium_runtest_makereport, repr_name_from_hook_name, hook_type_from_hook_name, is_fixture_a_module_hook, \
    is_fixture_a_class_hook, bdd_scenario_name, bdd_test_tags, store_pytest_bdd_test_status, store_pytest_test_status
from bstack_utils.selenium_patch import SeleniumPatch
from bstack_utils.session_utils import browserstack_executor_helper, get_nudge_local_error, update_caps_for_local, \
    mark_session_status, mark_pw_session_status
from bstack_utils.test_data import TestData
from bstack_utils.to_handler import TOHandler
import bstack_utils.accessibility as a11y
from bstack_utils.testhub_handler import TestHubHandler
from bstack_utils.accessibility_scripts import accessibility_scripts
from bstack_utils.orchestration_utils import OrchestrationUtils
from browserstack_sdk.__init__ import get_turboscale_playwright_url

from browserstack_sdk.sdk_cli.module_event_dispatcher import EventDispatcherModule
from browserstack_sdk.sdk_cli.event_bus import event_bus, Events, ConnectEvent
from browserstack_sdk.sdk_cli.test_framework import TestFrameworkContext, TestFrameworkState, TestHookState
from browserstack_sdk.sdk_cli.cli import cli
from browserstack_sdk.sdk_cli.event_bus import event_bus, Events, ConnectEvent

# global variables to store original methods, will be populated when needed
orig_init = None
orig_quit = None
orig_test_status_init = None
orig_sel_lib_ff_prof = None
orig_queueitem_init = None
orig_create_command_for_execution = None
orig_get_proxy_url = None
orig_close = None
orig_get = None
orig_popen_init = None
orig_pytest_get_option = None
orig_pytest_update_current_test_var = None
orig_pytest_bdd_runtest_makereport = None

FRAMEWORK_NAME = ''
CONFIG = {}
IS_APP_AUTOMATE = False
HUB_URL = ''
DEFAULT_LOCAL_ID = ''
PARALLELISE_VANILLA_PYTHON = False
SESSION_DRIVERS = []
LOG_LEVEL = DEFAULT_LOG_LEVEL
FRAMEWORK = 'pytest'
PLATFORM_CONFIG = {}
SESSION_NAME = None

# global flag to avoid recursion for a11y scans
IS_A11Y_SCAN_ONGOING = False

logger = logger_utils.get_logger(__name__, LOG_LEVEL)

store = {
    'current_hook_uuid': []
}

signal_handler_registered = False

try:
    from playwright.sync_api import (
        BrowserContext,
        Page
    )
except:
    pass

import json

_tests = {}
current_test_uuid = None
cli_context = TestFrameworkContext(
    test_framework_name=TEST_FRAMEWORK_NAME['PYTEST-BDD'] if is_pytest_bdd() else TEST_FRAMEWORK_NAME['PYTEST'],
    test_framework_version=pytest.__version__,
    platform_index=-1,
)

def playwright_set_session_name(page, sess_name):
    try:
        page.evaluate("_ => {}",
                      'browserstack_executor: {"action": "setSessionName", "arguments": {"name":' + json.dumps(
                          sess_name) + "}}")
    except Exception as e:
        print("exception in playwright session name {}", e)


def playwright_annotate(page, message, level):
    try:
        page.evaluate("_ => {}", 'browserstack_executor: {"action": "annotate", "arguments": {"data":' + json.dumps(
            message) + ',"level":' + json.dumps(level) + '}}')
    except Exception as e:
        print("exception in playwright annotation {}", e)


def pytest_configure(config):
    global HUB_URL
    global CONFIG

    global_config = Config.get_instance()
    config.args = TOHandler.get_pytest_rerun_specs(config.args)
    global_config.set_skip_session_status(is_true(config.getoption('skipSessionStatus')))
    try:
        logger_utils.save_pytest_config_paths(config.inipath, config.rootpath)
    except:
        pass

    if cli.is_running():
        event_bus.invoke(Events.CONNECT, ConnectEvent())

        # TODO: temporary. this is supposed to arrive from the CLI-side in module_webdriver.py
        cli_context.platform_index = int(os.environ.get('BROWSERSTACK_PLATFORM_INDEX', '0'))
        config = json.loads(os.environ.get("BROWSERSTACK_CONFIG", "{}"))
        # config_capabilities = get_caps(config, cli_context.platform_index) if isinstance(config, dict) else dict()
        # options = create_options_from_caps(cli.capabilities)
        cli.setup_selenium(get_hub_url(HUB_URL, CONFIG), cli_context.platform_index, create_options_from_caps)

    if cli.is_module_loaded(EventDispatcherModule):
        cli.setup_test_framework()

        logger.debug(f"CLI is active for platform_index={cli_context.platform_index}")
        cli.test_framework.track_event(cli_context, TestFrameworkState.BEFORE_ALL, TestHookState.PRE, config)


@pytest.hookimpl(hookwrapper=True)
def pytest_runtest_makereport(item, call):
    when = getattr(call, "when", None)

    if cli.is_running() and when == "call":
        cli.test_framework.track_event(cli_context, TestFrameworkState.LOG_REPORT, TestHookState.PRE, item, call)

    outcome = yield

    if when == "call":
        report = outcome.get_result()
        passed = report.passed or report.skipped or (report.failed and hasattr(report, "wasxfail"))
        if not passed:
            config = json.loads(os.environ.get("BROWSERSTACK_CONFIG", "{}"))
            if OrchestrationUtils.is_retry_enabled(config):
                retry_count = OrchestrationUtils.get_retry_count(config)
                if item.execution_count > retry_count:
                    # If the test has already been retried, mark it as failed
                    print('Test failed after retries: ', report.nodeid, os.environ.get('BROWSERSTACK_TESTHUB_UUID'))
                    OrchestrationUtils.write_failure_to_file(report.nodeid)
            else:
                print('Test failed: ', report.nodeid, os.environ.get('BROWSERSTACK_TESTHUB_UUID'))
                OrchestrationUtils.write_failure_to_file(report.nodeid)
        else:
            print('Test passed: ', report.nodeid, os.environ.get('BROWSERSTACK_TESTHUB_UUID'))

    if cli.is_running():
        if when == "setup":
            cli.test_framework.track_event(cli_context, TestFrameworkState.BEFORE_EACH, TestHookState.POST, item, call, outcome)
        elif when == "call":
            cli.test_framework.track_event(cli_context, TestFrameworkState.LOG_REPORT, TestHookState.POST, item, call, outcome)
        elif when == "teardown":
            cli.test_framework.track_event(cli_context, TestFrameworkState.AFTER_EACH, TestHookState.POST, item, call, outcome)
        return # skip all existing operations

    skipSessionName = item.config.getoption('skipSessionName')
    plugins = item.config.getoption("plugins")

    report = outcome.get_result()
    os.environ['PYTEST_TEST_NAME'] = report.nodeid
    handle_o11y_test_event(item, call, report)
    if "pytest_browserstackplugin" not in plugins or is_pytest_bdd():
        return

    summary = []
    driver = getattr(item, "_driver", None)
    page = getattr(item, "_page", None)
    try:
        if (driver == None or driver.session_id == None):
            driver = threading.current_thread().bstackSessionDriver
    except:
        pass
    item._driver = driver

    if (driver is not None or cli.is_running()):
        browserstackplugin_runtest_makereport_selenium(item, report, summary, skipSessionName)

    if (page is not None):
        browserstackplugin_runtest_makereport_playwright(item, report, summary, skipSessionName)


def browserstackplugin_runtest_makereport_selenium(item, report, summary, skipSessionName):
    if report.when == 'setup' and report.skipped:
        store_pytest_test_status(report)

    if report.when in ["setup", "teardown"]:
        return

    if not is_bstack_automation():
        return

    try:
        if ((str(skipSessionName).lower() != 'true') and (not cli.is_running())) and item._driver.session_id:
            item._driver.execute_script(
                'browserstack_executor: {"action": "setSessionName", "arguments": {"name": ' + json.dumps(
                    report.nodeid) + '}}')
        os.environ['PYTEST_TEST_NAME'] = report.nodeid
    except Exception as e:
        summary.append(
            "WARNING: Failed to mark session name: {0}".format(e)
        )

    passed = report.passed or report.skipped or (report.failed and hasattr(report, "wasxfail"))
    # set test failure reason if available
    fail_reason = ""

    store_pytest_test_status(report)

    if not passed:
        try:
            fail_reason = report.longrepr.reprcrash
        except Exception as e:
            summary.append(
                "WARNING: Failed to determine failure reason: {0}".format(e)
            )
        try:
            if (threading.current_thread().bstackTestErrorMessages == None):
                threading.current_thread().bstackTestErrorMessages = []
        except Exception as e:
            threading.current_thread().bstackTestErrorMessages = []
        threading.current_thread().bstackTestErrorMessages.append(str(fail_reason))

    if not report.skipped:
        passed = report.passed or (report.failed and hasattr(report, "wasxfail"))
        # set test failure reason if available
        fail_reason = ""
        if not passed:
            try:
                fail_reason = report.longrepr.reprcrash
            except Exception as e:
                summary.append(
                    "WARNING: Failed to determine failure reason: {0}".format(e)
                )
            try:
                if (threading.current_thread().bstackTestErrorMessages == None):
                    threading.current_thread().bstackTestErrorMessages = []
            except Exception as e:
                threading.current_thread().bstackTestErrorMessages = []
            threading.current_thread().bstackTestErrorMessages.append(str(fail_reason))

        try:
            if passed:
                item._driver.execute_script(
                    'browserstack_executor: {\
                            "action": "annotate", \
                            "arguments": {\
                                "level": "info", \
                                "data": '
                    + json.dumps("passed!")
                    + "\
                            }\
                        }"
                )
            else:
                item._driver.execute_script(
                    'browserstack_executor: {\
                            "action": "annotate", \
                            "arguments": {\
                                "level": "error", \
                                "data": '
                    + json.dumps(str(fail_reason))
                    + "\
                            }\
                        }"
                )
        except Exception as e:
            summary.append("WARNING: Failed to annotate: {0}".format(e))

def store_pw_pytest_error_list(test_name, error_message):
    try:
        pw_pytest_error_list = []
        p_index = os.environ.get('BROWSERSTACK_PLATFORM_INDEX', '0')
        current_test_errors = {'name': test_name, 'error': error_message, 'index': p_index}
        pw_pytest_error_list_path = os.path.join(tempfile.gettempdir(), 'pw_pytest_error_list.json')
        if os.path.exists(pw_pytest_error_list_path):
            with open(pw_pytest_error_list_path) as f:
                pw_pytest_error_list = json.load(f)

        pw_pytest_error_list.append(current_test_errors)
        with open(pw_pytest_error_list_path, 'w') as f:
            json.dump(pw_pytest_error_list, f)
    except Exception as e:
        logger.debug('Error in persisting playwright pytest errors: ' + str(e))

def browserstackplugin_runtest_makereport_playwright(item, report, summary, skipSessionName):
    if report.when in ["setup", "teardown"]:
        return

    if (str(skipSessionName).lower() != 'true'):
        playwright_set_session_name(item._page, report.nodeid)
    passed = report.passed or report.skipped or (report.failed and hasattr(report, "wasxfail"))
    # set test failure reason if available
    fail_reason = ""

    store_pytest_test_status(report)

    if not report.skipped:
        if not passed:
            try:
                fail_reason = report.longrepr.reprcrash
            except Exception as e:
                summary.append(
                    "WARNING: Failed to determine failure reason: {0}".format(e)
                )
        try:
            if passed:
                mark_pw_session_status(getattr(item, '_page', None), "passed")
            else:
                error_message = ''
                if fail_reason:
                    playwright_annotate(item._page, str(fail_reason), "error")
                    mark_pw_session_status(getattr(item, '_page', None), "failed", str(fail_reason))

                    error_message = str(fail_reason)
                else:
                    mark_pw_session_status(getattr(item, '_page', None), "failed")

                store_pw_pytest_error_list(report.nodeid, error_message)

        except Exception as e:
            summary.append("WARNING: Failed to update session status: {0}".format(e))

def pytest_addoption(parser):
    parser.addoption("--skipSessionName", default="False", help="Automatic set session name")
    parser.addoption("--skipSessionStatus", default="False", help="Automatic set session name")
    try:
        import pytest_selenium.pytest_selenium
    except:
        parser.addoption("--driver", action="store", default="chrome",
                         help="Driver to run tests")


def log_handler(log):
    if not (log['message'] and log['message'].strip()):
        return

    active = get_active_test_or_hook()
    log = {
        'level': log['level'],
        'timestamp': get_utcnow_wo_tzinfo().isoformat() + 'Z',
        'message': log['message'],
    }

    if active:
        if active['type'] == 'hook':
            log['hook_run_uuid'] = active['hook_run_uuid']
        elif active['type'] == 'test':
            log['test_run_uuid'] = active['test_run_uuid']

    TestHubHandler.send_logs([log])


def get_active_test_or_hook():
    if len(store['current_hook_uuid']) > 0 and store['current_hook_uuid'][-1]:
        return {
            'type': 'hook',
            'hook_run_uuid': store['current_hook_uuid'][-1]
        }

    if store.get('current_test_uuid', None):
        return {
            'type': 'test',
            'test_run_uuid': store['current_test_uuid']
        }

    return None


# capture_logs = CaptureLogs(log_handler)


def pytest_runtest_logstart(nodeid, location):
    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.INIT_TEST, TestHookState.PRE, nodeid, location)


def pytest_runtest_logfinish(nodeid, location):
    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.INIT_TEST, TestHookState.POST, nodeid, location)


def pytest_runtest_call(item):
    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.TEST, TestHookState.PRE, item)
        return

    try:
        global CONFIG

        item._test_case_started = True
        is_a11y = a11y.is_enabled_testcase(get_tags_from_markers(item.own_markers))


        if not cli.is_module_loaded(EventDispatcherModule):
            # Don't use a11y test case solely, use it along with 'a11yPlatform' as it doesn't check for platform
            item._a11y_test_case = is_a11y
            if get_thread_value_or_default(threading.current_thread(), 'a11yPlatform', None):
                driver = getattr(item, '_driver', None)
                item._a11y_started = a11y.start_test_capture(driver, is_a11y)

        if not TestHubHandler.on() or FRAMEWORK != 'pytest':
            return
        global current_test_uuid #, capture_logs
        # capture_logs.start()
        test_meta_data = {
            'uuid': uuid4().__str__(),
            'started_at': get_utcnow_wo_tzinfo().isoformat() + 'Z'
        }

        current_test_uuid = test_meta_data['uuid']
        store['current_test_uuid'] = test_meta_data['uuid']
        threading.current_thread().current_test_uuid = current_test_uuid
        _tests[item.nodeid] = {**_tests[item.nodeid], **test_meta_data}
        send_test_run_event(item, _tests[item.nodeid], 'TestRunStarted')
    except Exception as err:
        print('Exception in pytest_runtest_call: {}', str(err))


def pytest_runtest_setup(item):
    store['current_test_item'] = item
    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.BEFORE_EACH, TestHookState.PRE, item, 'setup')

    if OrchestrationUtils.check_abort_build_file_exists():
            skip_reason = "Skipping test as the abort build file exists."
            logger.error(skip_reason)
            # Send "TestRunSkipped" event to TestHub
            test_meta_data = {
                'uuid': uuid4().__str__(),
                'started_at': get_utcnow_wo_tzinfo().isoformat() + 'Z',
                'finished_at': get_utcnow_wo_tzinfo().isoformat() + 'Z',
                'result': 'skipped',
                'reason': skip_reason,
                'hooks': [],
                'fixtures': []
            }

            # cli.test_framework.track_event(cli_context, TestFrameworkState.SKIPPED, TestHookState.POST, item)
            send_test_run_event(item, test_meta_data, 'TestRunSkipped')
            pytest.skip(skip_reason)
            return # skip all existing operations

    global signal_handler_registered
    threading.current_thread().percySessionName = item.nodeid

    if is_browserstack_session():
        atexit.register(bstack_exit_handler)
        if not signal_handler_registered:
            try:
                signal_list = [signal.SIGINT, signal.SIGTERM]
                if not is_windows():
                    signal_list.extend([signal.SIGHUP, signal.SIGQUIT])

                for s in signal_list:
                    signal.signal(s, signal_handler)
                signal_handler_registered = True
            except Exception as e:
                logger.debug(
                    "Error in register signal handlers: " + str(e))

        try:
            item.config.hook.pytest_selenium_runtest_makereport = mod_pytest_selenium_runtest_makereport
        except Exception as err:
            threading.current_thread().testStatus = 'passed'

    try:
        if not TestHubHandler.on():
            return
        # capture_logs.start()
        uuid = uuid4().__str__()
        test_meta_data = {
            'uuid': uuid,
            'started_at': get_utcnow_wo_tzinfo().isoformat() + 'Z',
            'type': 'hook',
            'hook_type': 'BEFORE_EACH',
            'hook_name': 'setup'
        }
        threading.current_thread().current_hook_uuid = uuid

        # Storing in thread to be able to use in mod_quit in init (in case of ppp - 1)
        threading.current_thread().current_test_item = item
        store['current_test_item'] = item
        store['current_hook_uuid'] = [uuid]
        if not _tests.get(item.nodeid, None):
            _tests[item.nodeid] = {'hooks': [], 'fixtures': []}

        _tests[item.nodeid]['hooks'].append(test_meta_data['uuid'])
        _tests[item.nodeid + '-setup'] = test_meta_data
        send_hook_run_event(item, test_meta_data, 'HookRunStarted')
    except Exception as err:
        print('Exception in pytest_runtest_setup: {}', str(err))


def pytest_runtest_teardown(item):
    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.TEST, TestHookState.POST, item)
        cli.test_framework.track_event(cli_context, TestFrameworkState.AFTER_EACH, TestHookState.PRE, item, 'teardown')
        return # skip all existing operations

    try:
        global PLATFORM_CONFIG
        p_index = 0
        if PARALLELISE_VANILLA_PYTHON is True:
            p_index = int(os.environ.get('BROWSERSTACK_PLATFORM_INDEX'))
        if Percy.is_percy() == "true":
            if Percy.get_percy_capture_mode() == "testcase":
                percy_test_end = get_thread_value_or_default(threading.current_thread(), 'percySessionName', None)
                percy_test_end_ss_name = percy_test_end + "-testcase"
                driver = getattr(item, '_driver', None)
                testCase = getattr(item, 'name', None)
                thTestCaseExecutionId = getattr(item, 'uuid', None)
                PercySDK.screenshot(driver, percy_test_end_ss_name, testCase=testCase, thTestCaseExecutionId=thTestCaseExecutionId, platformIndex=p_index)

        if not cli.is_module_loaded(EventDispatcherModule):
            if getattr(item, '_a11y_started', False):
                PytestHandler.send_a11y_stop(getattr(item, '_driver', None), PLATFORM_CONFIG, logger, item)

        if not TestHubHandler.on():
            return
        test_meta_data = {
            'uuid': uuid4().__str__(),
            'started_at': get_utcnow_wo_tzinfo().isoformat() + 'Z',
            'type': 'hook',
            'hook_type': 'AFTER_EACH',
            'hook_name': 'teardown'
        }

        _tests[item.nodeid + '-teardown'] = test_meta_data
        send_hook_run_event(item, test_meta_data, 'HookRunStarted')
    except Exception as err:
        print('Exception in pytest_runtest_teardown: {}', str(err))


@pytest.hookimpl(hookwrapper=True)
def pytest_fixture_setup(fixturedef, request):
    if is_fixture_a_module_hook(fixturedef.argname):
        store['current_module_item'] = request.node
    elif is_fixture_a_class_hook(fixturedef.argname):
        store['current_class_item'] = request.node

    if not TestHubHandler.on():
        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState.SETUP_FIXTURE, TestHookState.PRE, fixturedef, request)

        outcome = yield

        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState.SETUP_FIXTURE, TestHookState.POST, fixturedef, request, outcome)
        return # skip all existing operations

    start_time = datetime.datetime.now()

    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.SETUP_FIXTURE, TestHookState.PRE, fixturedef, request)

    outcome = yield

    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.SETUP_FIXTURE, TestHookState.POST, fixturedef, request, outcome)
        return # skip all existing operations

    try:
        fixture = {
            'name': fixturedef.argname,
            'result': get_outcome_status(outcome),
            'duration': (datetime.datetime.now() - start_time).total_seconds() * 1000
        }

        current_test_item = store['current_test_item']
        if not _tests.get(current_test_item.nodeid, None):
            _tests[current_test_item.nodeid] = {'fixtures': []}

        _tests[current_test_item.nodeid]['fixtures'].append(fixture)
    except Exception as err:
        logger.debug('Exception in pytest_fixture_setup: {}', str(err))


if is_pytest_bdd() and TestHubHandler.on():
    def pytest_bdd_before_step(request, step):
        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState.STEP, TestHookState.PRE, request, step)
            return
        try:
            _tests[request.node.nodeid]['test_data'].start_step(id(step))
        except Exception as err:
            print('Exception in pytest_bdd_before_step: {}', str(err))


    def pytest_bdd_step_error(request, step, exception):
        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState.STEP, TestHookState.POST, request, step, exception)
            return

        try:
            _tests[request.node.nodeid]['test_data'].stop_step(id(step), Result.failed(exception=exception))
        except Exception as err:
            print('Exception in pytest_bdd_step_error: {}', str(err))


    def pytest_bdd_after_step(request, step):
        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState.STEP, TestHookState.POST, request, step)
            return

        try:
            test_data: TestData = _tests[request.node.nodeid]['test_data']
            test_data.stop_step(id(step), Result.passed())
        except Exception as err:
            print('Exception in pytest_bdd_step_error: {}', str(err))


    def pytest_bdd_before_scenario(request, feature, scenario):
        global FRAMEWORK
        try:
            if not TestHubHandler.on() or FRAMEWORK != 'pytest-bdd':
                return

            if cli.is_running():
                cli.test_framework.track_event(cli_context, TestFrameworkState.TEST, TestHookState.PRE, request, feature, scenario)
                return

            # global capture_logs
            # capture_logs.start()

            driver = get_thread_value_or_default(threading.current_thread(), 'bstackSessionDriver', None)

            if not _tests.get(request.node.nodeid, None):
                _tests[request.node.nodeid] = {}

            test_data = TestData.for_pytest_bdd(
                scenario, feature, request.node,
                name=bdd_scenario_name(request.node, scenario),
                started_at=current_time(),
                file_path=feature.filename,
                scope=[feature.name],
                framework='Pytest-cucumber',
                tags=bdd_test_tags(feature, scenario),
                integrations=TestHubHandler.integrations_object(driver) if driver and driver.session_id else {}
            )

            _tests[request.node.nodeid]['test_data'] = test_data
            set_current_test(test_data.uuid)
            TestHubHandler.send_run_event('TestRunStarted', test_data)
        except Exception as err:
            print('Exception in pytest_bdd_before_scenario: {}', str(err))


def remove_current_hook(hook_uuid):
    if hook_uuid in store['current_hook_uuid']:
        store['current_hook_uuid'].remove(hook_uuid)


def set_current_test(test_uuid):
    store['current_test_uuid'] = test_uuid
    threading.current_thread().current_test_uuid = test_uuid


@TestHubHandler.need_th
def handle_o11y_test_event(item, call, report):
    logger.debug('handle_o11y_test_event: start')
    global FRAMEWORK
    curr_time = current_time()
    if hasattr(report, 'stop'):
        curr_time = iso_from_timestamp(report.stop)
    elif hasattr(report, 'start'):
        curr_time = iso_from_timestamp(report.start)
    try:
        # if getattr(report, 'when', '') == 'call':
        #     capture_logs.reset()

        if getattr(report, 'when', '') == 'call':
            logger.debug('handle_o11y_test_event: state - {}, framework - {}'.format(getattr(report, 'when', '').__str__(), FRAMEWORK))
            if FRAMEWORK == 'pytest':
                _tests[item.nodeid]['finished_at'] = curr_time
                send_test_run_event(item, _tests[item.nodeid], 'TestRunFinished', report, call)
                store['current_test_uuid'] = None
            elif FRAMEWORK == "pytest-bdd":
                test_data = _tests[item.nodeid]['test_data']
                test_data.set(hooks=_tests[item.nodeid].get('hooks', []))
                exception, custom_traceback = None, None
                if call.excinfo:
                    exception = call.excinfo.value
                    custom_traceback = [call.excinfo.exconly(), getattr(report, 'longreprtext', '')]
                test_data.stop(time=curr_time, result=Result(result=getattr(report, 'outcome', 'passed'), exception=exception, custom_traceback=custom_traceback))
                TestHubHandler.send_run_event('TestRunFinished', _tests[item.nodeid]['test_data'])

        elif getattr(report, 'when', '') in ['setup', 'teardown']:
            logger.debug('handle_o11y_test_event: state - {}, framework - {}'.format(getattr(report, 'when', '').__str__(), FRAMEWORK))
            hook_id = item.nodeid + '-' + getattr(report, 'when', '')
            if getattr(report, 'skipped', False):
                hook_type = 'BEFORE_EACH' if getattr(report, 'when', '') == 'setup' else 'AFTER_EACH'
                _tests[hook_id] = {
                    'uuid': uuid4().__str__(),
                    'started_at': curr_time,
                    'hook_type': hook_type
                }

            _tests[hook_id]['finished_at'] = curr_time
            remove_current_hook(_tests[hook_id]['uuid'])
            send_hook_run_event(item, _tests[hook_id], 'HookRunFinished', report, call)
            if getattr(report, 'when', '') == 'setup':
                if getattr(report, 'outcome', 'passed') == 'failed':
                    test_meta_data = {
                        'uuid': uuid4().__str__(),
                        'started_at': current_time(),
                        'finished_at': current_time()
                    }
                    _tests[item.nodeid] = {**_tests[item.nodeid], **test_meta_data}
                    send_test_run_event(item, _tests[item.nodeid], 'TestRunStarted')
                    send_test_run_event(item, _tests[item.nodeid], 'TestRunFinished', report, call)
    except Exception as err:
        print('Exception in handle_o11y_test_event: {}', str(err))


def test_object(test, test_meta_data, result=None, call=None, event_type=None, outcome=None):
    file_path = os.path.relpath(test.fspath.strpath, start=os.getcwd())
    test_data = {
        'uuid': test_meta_data['uuid'],
        'type': 'test',
        'name': test.name,
        'body': {
            'lang': 'python',
            'code': inspect.getsource(test.obj)
        },
        'identifier': test.name,
        'scope': test.name,
        'scopes': TOHandler.get_scope_of_test(test),
        'file_name': file_path,
        'location': file_path,
        'result': 'pending',
        'vc_filepath': file_path,
        'started_at': test_meta_data['started_at'],
        'framework': 'Pytest',
        'customRerunParam': {
            'rerun_name': test.nodeid
        },
        'tags': get_tags_from_markers(test.own_markers)
    }

    if event_type in ['TestRunSkipped', 'TestRunFinished']:
        test_data['meta'] = {
            'fixtures': test_meta_data.get('fixtures', [])
        }

    if event_type == 'TestRunSkipped':
        test_data['result'] = 'skipped'
        test_data['hooks'] = test_meta_data['hooks']
        test_data['finished_at'] = test_meta_data['finished_at']

    if result:
        test_data['result'] = result.outcome
        test_data['duration_in_ms'] = result.duration * 1000  # TODO: for setup failed tests
        test_data['finished_at'] = test_meta_data['finished_at']
        if result.failed:
            test_data['failure_type'] = TestHubHandler.failure_type(call.excinfo.typename)
            test_data['failure'] = TestHubHandler.failure_data(call.excinfo, result)
        test_data['hooks'] = test_meta_data['hooks']

    if outcome:  # TODO
        test_data['result'] = get_outcome_status(outcome)
        test_data['duration_in_ms'] = 0
        test_data['finished_at'] = test_meta_data['finished_at']
        if test_data['result'] == 'failed':
            test_data['failure_type'] = 'UnhandledError'  # TODO
            test_data['failure'] = [{'backtrace': ['some error']}]
        test_data['hooks'] = test_meta_data['hooks']
    return test_data


def hook_object(test, hook_meta_data, event_type, result, call, outcome, custom_result):
    file_path = os.path.relpath(test.fspath.strpath, start=os.getcwd())
    hook_type = hook_meta_data['hook_type']
    hook_name = hook_meta_data['hook_name']
    hook_data = {
        'uuid': hook_meta_data['uuid'],
        'type': 'hook',
        'name': '{}'.format(repr_name_from_hook_name(hook_name)),
        'body': {
            'lang': 'python',
            'code': None
        },
        'scope': test.name,
        'scopes': TOHandler.get_scope_of_test(test, hook_name),
        'file_name': file_path,
        'location': file_path,
        'result': 'pending',
        'vc_filepath': file_path,
        'started_at': hook_meta_data['started_at'],
        'framework': 'Pytest-cucumber' if FRAMEWORK == 'pytest-bdd' else 'Pytest',
        'hook_type': hook_type
    }

    test_run_id = uuid_from_tests_obj(_tests.get(test.nodeid, None))
    if test_run_id:
        hook_data['test_run_id'] = test_run_id

    if result:
        hook_data['result'] = result.outcome
        hook_data['duration_in_ms'] = result.duration * 1000
        hook_data['finished_at'] = hook_meta_data['finished_at']
        if result.failed:
            hook_data['failure_type'] = TestHubHandler.failure_type(call.excinfo.typename)
            hook_data['failure'] = TestHubHandler.failure_data(call.excinfo, result)

    if outcome:  # TODO
        hook_data['result'] = get_outcome_status(outcome)
        hook_data['duration_in_ms'] = 100  # TODO: get duration from finish - start
        hook_data['finished_at'] = hook_meta_data['finished_at']
        if hook_data['result'] == 'failed':
            hook_data['failure_type'] = 'UnhandledError'  # TODO
            hook_data['failure'] = [{'backtrace': ['some error']}]

    if custom_result:
        hook_data['result'] = custom_result.result
        hook_data['duration_in_ms'] = time_diff(hook_meta_data['started_at'], hook_meta_data['finished_at'])
        hook_data['finished_at'] = hook_meta_data['finished_at']
        if hook_data['result'] == 'failed':
            hook_data['failure_type'] = TestHubHandler.failure_type(custom_result.exception_type)
            hook_data['failure'] = [{'backtrace': get_backtrace_from_exception(custom_result.exception)}]

    return hook_data


def send_test_run_event(test, test_meta_data, event_type, result=None, call=None, outcome=None):
    logger.debug('send_test_run_event: Attempting to generate test data for event_type - {}'.format(event_type))
    test_data = test_object(test, test_meta_data, result, call, event_type, outcome)
    driver = getattr(test, '_driver', None)

    if event_type == 'TestRunStarted' and driver:
        test_data['integrations'] = TestHubHandler.integrations_object(driver)

    if event_type == 'TestRunSkipped':
        event_type = 'TestRunFinished'

    upload_data = {
        'event_type': event_type,
        'test_run': test_data
    }
    TestHubHandler.send_data(upload_data)
    if event_type == 'TestRunStarted':
        threading.current_thread().bstackTestMeta = {'status': 'pending'}
    elif event_type == 'TestRunFinished':
        threading.current_thread().bstackTestMeta = {'status': getattr(result, 'outcome', '')}


def send_hook_run_event(test, test_meta_data, event_type, result=None, call=None, outcome=None, custom_result=None):
    logger.debug('send_hook_run_event: Attempting to generate hook data, eventType - {}'.format(event_type))
    hook_data = hook_object(test, test_meta_data, event_type, result, call, outcome, custom_result)
    upload_data = {
        'event_type': event_type,
        'hook_run': hook_data
    }
    TestHubHandler.send_data(upload_data)


def uuid_from_tests_obj(test_meta_data):
    if not test_meta_data:
        return None

    if test_meta_data.get('test_data', None):
        return getattr(test_meta_data['test_data'], 'uuid', None)

    return test_meta_data.get('uuid', None)


@pytest.fixture(autouse=True)
def second_fixture(caplog, request):
    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.LOG, TestHookState.PRE, request, caplog)

    yield

    if cli.is_running():
        cli.test_framework.track_event(cli_context, TestFrameworkState.LOG, TestHookState.POST, request, caplog)
        return # skip all existing operations

    try:
        if not TestHubHandler.on():
            return

        places = ['setup', 'call', 'teardown']
        logs = []

        for place in places:
            records = caplog.get_records(place)
            run_key = 'test_run_uuid' if place == 'call' else 'hook_run_uuid'
            test_key = request.node.nodeid + ('' if place == 'call' else '-' + place)
            test_uuid = uuid_from_tests_obj(_tests.get(test_key, None))
            if not test_uuid:
                continue
            for record in records:
                if empty_log(record.message):
                    continue

                logs.append({
                    'timestamp': get_utcfromtimestamp_wo_tzinfo(record.created).isoformat() + 'Z',
                    'level': record.levelname,
                    'message': record.message,
                    run_key: test_uuid
                })

        if len(logs) > 0:
            TestHubHandler.send_logs(logs)
    except Exception as err:
        print('Exception in second_fixture: {}', str(err))


def selenium_handler(sequence, driver_command, response=None, driver = None, args = None):
    global IS_A11Y_SCAN_ONGOING

    is_a11y_test_thread = get_thread_value_or_default(threading.current_thread(), 'isA11yTest', None) and get_thread_value_or_default(
            threading.current_thread(), 'a11yPlatform', None)
    is_a11y_scan_started_on_driver = getattr(driver, 'bstackA11yShouldScan', None) != None and getattr(driver, 'bstackA11yShouldScan', None) == True

    if sequence == 'before' and driver != None:
      if not IS_A11Y_SCAN_ONGOING and is_bstack_automation() and 'accessibility' in CONFIG and CONFIG['accessibility'] == True and accessibility_scripts.should_wrap_command(driver_command) and (is_a11y_scan_started_on_driver or is_a11y_test_thread) and not is_browserstack_executor_script(args):
        try:
          IS_A11Y_SCAN_ONGOING = True
          logger.debug('Performing scan for {}'.format(driver_command))
          logger.debug(perform_scan(driver, driver_command=driver_command))
        except Exception as err:
          logger.debug('Failed to perform scan {}'.format(str(err)))
        IS_A11Y_SCAN_ONGOING = False

    if sequence == 'after':
        if driver_command == 'screenshot':
            TestHubHandler.send_screenshot({
                'image': response['value'],
                'test_run_uuid': store['current_test_uuid']
            })

def bstack_exit_handler():
    global SESSION_DRIVERS
    logger_utils.clear_handlers()
    logging.shutdown()
    TestHubHandler.flush_data()
    for driver in SESSION_DRIVERS:
        try:
            driver.quit()
        except Exception as e:
            pass


def signal_handler(*args):
    global SESSION_DRIVERS
    TestHubHandler.flush_data()
    for driver in SESSION_DRIVERS:
        try:
            driver.quit()
        except Exception as e:
            pass

@measure(event_name=EVENTS.SDK_POST_INITIALIZE, stage=STAGE.SINGLE, session_name=SESSION_NAME)
def mod_init_o11y(self, *args, **kwargs):
    ret_val = orig_init(self, *args, **kwargs)
    current_test_meta = getattr(threading.current_thread(), 'bstackTestMeta', None)
    if current_test_meta and current_test_meta.get('status', '') == 'pending':
        TestHubHandler.send_cbt_info(self)
    return ret_val

@measure(event_name=EVENTS.SDK_BS_SETUP, stage=STAGE.START, session_name=SESSION_NAME)
def mod_for_browserstack(framework_name):
    from bstack_utils.config import Config
    global_config = Config.get_instance()
    # Returning to prevent duplicate patching in single process,
    # it can issues like duplicated values in an array etc.
    if global_config.get_property('bstack_mod_called'):
        return

    global_config.set_property('bstack_mod_called', True)

    # add patch method here when framework is pytest
    global FRAMEWORK_NAME
    global SELENIUM_OR_PLAYWRIGHT_INSTALLED
    FRAMEWORK_NAME = framework_name
    logger.info(SETUP_START.format(FRAMEWORK_NAME.split('-')[0]))

    try:
        from selenium import webdriver
        from selenium.webdriver.common.service import Service
        from selenium.webdriver.remote.webdriver import WebDriver

        if is_bstack_automation():
            Service.start = mod_start
            Service.stop = mod_stop
            webdriver.Remote.get = mod_get
            webdriver.Remote.__init__ = mod_init

            # skip patching methods test level parallelisation not enabled
            # so that quit can be invoked inside exit handler and avoid IDLE_TIMEOUTS
            if not isinstance(os.getenv('BROWSERSTACK_PYTEST_PARALLEL'), str):
                return
            WebDriver.quit = mod_quit

            # a11y methods
            WebDriver.getAccessibilityResults = getAccessibilityResults
            WebDriver.get_accessibility_results = getAccessibilityResults
            WebDriver.getAccessibilityResultsSummary = getAccessibilityResultsSummary
            WebDriver.get_accessibility_results_summary = getAccessibilityResultsSummary
            WebDriver.performScan = perform_scan
            WebDriver.perform_scan = perform_scan
        elif TestHubHandler.on():
            webdriver.Remote.__init__ = mod_init_o11y
        SELENIUM_OR_PLAYWRIGHT_INSTALLED = True
    except Exception as e:
        pass
    if os.environ.get('SELENIUM_OR_PLAYWRIGHT_INSTALLED'):
        SELENIUM_OR_PLAYWRIGHT_INSTALLED = eval(os.environ.get('SELENIUM_OR_PLAYWRIGHT_INSTALLED'))
    if not SELENIUM_OR_PLAYWRIGHT_INSTALLED:
        import_error_handler("Packages not installed", IMPORT_ERROR_SEL_PW)
    if should_set_user_hub_proxy_for_selenium():
        try:
            from selenium.webdriver.remote.remote_connection import RemoteConnection
            if hasattr(RemoteConnection, '_get_proxy_url') and callable(getattr(RemoteConnection, '_get_proxy_url')):
                # not obfuscating `_get_proxy_url` since the method has been removed >= 4.26.0, breaking version < 4.26.0
                RemoteConnection._get_proxy_url = mod_get_proxy_url
            else:
                from selenium.webdriver.remote.client_config import ClientConfig
                ClientConfig.get_proxy_url = mod_get_proxy_url
        except Exception as e:
            logger.error(PROXY_SETUP_ERROR.format(str(e)))
    if 'pytest' in str(framework_name).lower():
        if not is_bstack_automation():
            return

        try:
            from pytest_selenium import pytest_selenium
            from _pytest.config import Config
            pytest_selenium.pytest_report_header = mod_pytest_report_header
            from pytest_selenium.drivers import browserstack
            browserstack.pytest_selenium_runtest_makereport = mod_pytest_bstack_makereport
            Config.getoption = mod_pytest_get_option
        except Exception as e:
            pass
        try:
            from pytest_bdd import reporting
            reporting.runtest_makereport = mod_pytest_bdd_runtest_makereport
        except Exception as e:
            pass

@measure(event_name=EVENTS.SDK_DRIVER_QUIT, stage=STAGE.SINGLE, session_name=SESSION_NAME)
def mod_quit(self):
    global FRAMEWORK_NAME
    global SESSION_ID
    global orig_quit
    try:
        if 'pytest' in FRAMEWORK_NAME and self.session_id != None and get_thread_value_or_default(threading.current_thread(), 'testStatus', '') != 'skipped':
            finalStatus = 'passed' if len(threading.current_thread().bstackTestErrorMessages) == 0 else 'failed'
            store_pytest_error_list(logger, True)
            if os.environ.get('PYTEST_TEST_NAME', None):
                self.execute_script(
                    'browserstack_executor: {"action": "setSessionName", "arguments": {"name": ' + json.dumps(
                        os.environ.get('PYTEST_TEST_NAME')) + '}}')
            if self != None:
                mark_session_status(self, finalStatus, ', '.join(threading.current_thread().bstackTestErrorMessages))

        if not cli.is_module_loaded(EventDispatcherModule):
            # Send A11y test end
            item = store.get('current_test_item', None)
            if item is not None and get_thread_value_or_default(threading.current_thread(), 'a11yPlatform', None):
                PytestHandler.send_a11y_stop(self, PLATFORM_CONFIG, logger, item)

        threading.current_thread().testStatus = ''
    except Exception as e:
        logger.debug("Error while marking status: " + str(e))
    orig_quit(self)
    self.session_id = None

@measure(event_name=EVENTS.SDK_PRE_INITIALIZE, stage=STAGE.SINGLE, session_name=SESSION_NAME)
def mod_init(self, command_executor,
             desired_capabilities=None, browser_profile=None, proxy=None,
             keep_alive=True, file_detector=None, options=None):
    global CONFIG
    global SESSION_ID
    global SESSION_NAME
    global PARALLELISE_VANILLA_PYTHON
    global FRAMEWORK_NAME
    global orig_init
    global SESSION_DRIVERS
    global HUB_URL
    global DEFAULT_LOCAL_ID
    global PLATFORM_CONFIG

    # set the identifier cap for sdk used
    CONFIG['browserstackSDK'] = str(FRAMEWORK_NAME) + str(__version__)

    command_executor = get_hub_url(HUB_URL, CONFIG)
    logger.debug(REMOTE_HUB.format(command_executor))
    proxy = set_browser_proxy(CONFIG, proxy)

    p_index = 0
    try:
        if PARALLELISE_VANILLA_PYTHON is True:
            p_index = int(os.environ.get('BROWSERSTACK_PLATFORM_INDEX'))
    except:
        p_index = 0
    caps_from_conf = get_caps(CONFIG, p_index)
    logger.debug(CONFIG_FILE_CONTENT.format(str(caps_from_conf)))

    PLATFORM_CONFIG = CONFIG.get('platforms')[p_index]

    if 'browserstackLocal' in CONFIG and CONFIG['browserstackLocal']:
        update_caps_for_local(caps_from_conf, DEFAULT_LOCAL_ID)

    if a11y.is_enabled_platform(CONFIG, p_index) and a11y.is_platform_supported(caps_from_conf, options, desired_capabilities):
        threading.current_thread().a11yPlatform = True

        if not cli.is_module_loaded(EventDispatcherModule):
            a11y.set_capabilities(caps_from_conf, CONFIG)

    if desired_capabilities:
        # if there are desired_caps from user script, sanitize and convert to options
        sanitized_dc_caps = sanitize_config(desired_capabilities)
        sanitized_dc_caps['useW3C'] = is_w3c_mode(CONFIG)
        caps_from_dc = get_caps(sanitized_dc_caps)

        if caps_from_dc:
            caps_from_conf = update(caps_from_dc, caps_from_conf)
        # set dc to none, since caps_from_conf now contains merger of dc + yml
        desired_capabilities = None

    if options:
        update_options(options, caps_from_conf)

    if not options:
        options = create_options_from_caps(caps_from_conf)

    # from selenium 4.10.0 onwards proxy (along with desired_capabilites)
    # is not an argument for init, so set it inside options
    if proxy and selenium_version_used() >= version.parse('4.10.0'):
        options.proxy(proxy)

    if options and selenium_version_used() >= version.parse('3.8.0'):
        desired_capabilities = None

    if (
            not options and not desired_capabilities
    ) or (
            selenium_version_used() < version.parse('3.8.0') and not desired_capabilities
    ):
        desired_capabilities = {}
        desired_capabilities.update(caps_from_conf)

    logger.info(SETUP_COMPLETE)
    performance_tester.end(EVENTS.SDK_BS_SETUP.value, EVENTS.SDK_BS_SETUP.value + ":start",
                               EVENTS.SDK_BS_SETUP.value + ":end", True, None)

    try:
        if selenium_version_used() >= version.parse('4.10.0'):
            orig_init(self, command_executor=command_executor,
                      options=options, keep_alive=keep_alive, file_detector=file_detector, *args, **kwargs)
        elif selenium_version_used() >= version.parse('3.8.0'):
            orig_init(self, command_executor=command_executor,
                      desired_capabilities=desired_capabilities, options=options,
                      browser_profile=browser_profile, proxy=proxy,
                      keep_alive=keep_alive, file_detector=file_detector)
        elif selenium_version_used() >= version.parse('2.53.0'):
            orig_init(self, command_executor=command_executor,
                      desired_capabilities=desired_capabilities,
                      browser_profile=browser_profile, proxy=proxy,
                      keep_alive=keep_alive, file_detector=file_detector)
        else:
            orig_init(self, command_executor=command_executor,
                      desired_capabilities=desired_capabilities,
                      browser_profile=browser_profile, proxy=proxy,
                      keep_alive=keep_alive)
    except Exception as session_error:
        # Enhanced error logging for session creation failures
        logger.error(START_SESSION_FAILURE.format('BrowserStack', str(session_error)))
        raise session_error

    # get the optimal hub url from caps in response and change the url
    try:
        optimal_hub_url = ''
        if selenium_version_used() >= version.parse('4.0.0b1'):
            optimal_hub_url = self.caps.get("optimalHubUrl")
        else:
            optimal_hub_url = self.capabilities.get("optimalHubUrl")
        if optimal_hub_url:
            set_optimal_hub_urls(optimal_hub_url)
            if selenium_version_used() <= version.parse('3.13.0'):
                self.command_executor._url = "http://" + HUB_URL + ":80/wd/hub"
            else:
                self.command_executor._url = "https://" + optimal_hub_url + "/wd/hub"
            logger.debug(NEW_HUB_URL.format(optimal_hub_url))
        else:
            logger.debug(NEW_HUB_URL_ERROR.format("Optimal Hub not found"))
    except Exception as e:
        logger.debug(NEW_HUB_URL_ERROR.format(e))

    # storing session id for later
    SESSION_ID = self.session_id
    if 'pytest' in FRAMEWORK_NAME:
        # store session_id for later for pytest
        threading.current_thread().bstackSessionId = self.session_id
        threading.current_thread().bstackSessionDriver = self
        threading.current_thread().bstackTestErrorMessages = []

        # Store driver in test item in case the test is already started
        item = store.get('current_test_item', None)
        if item:
            test_case_started = getattr(item, '_test_case_started', False)
            if not getattr(item, '_driver', None) and test_case_started:
                setattr(store['current_test_item'], '_driver', self)
        current_test_meta = getattr(threading.current_thread(), 'bstackTestMeta', None)
        if current_test_meta and current_test_meta.get('status', '') == 'pending':
            TestHubHandler.send_cbt_info(self)
    # append into drivers array
    SESSION_DRIVERS.append(self)
    # this is to know if name was passed in config,
    # if so, later we'll not update the name based on context
    if 'platforms' in CONFIG and 'sessionName' in CONFIG['platforms'][p_index]:
        SESSION_NAME = CONFIG['platforms'][p_index]['sessionName']
    logger.debug(SESSION_STARTED_ID.format(SESSION_ID))

@measure(event_name=EVENTS.SDK_DRIVER_GET, stage=STAGE.SINGLE, session_name=SESSION_NAME)
def mod_get(self, url):
    global orig_get
    global CONFIG
    try:
        get_nudge_local_error(url, CONFIG, logger)
    except Exception as err:
        logger.debug(NUDGE_LOCAL_FUNC_EXCEPTION_ERROR.format(str(err)))
    try:
        orig_get(self, url)
    except Exception as e:
        try:
            parsed_error = str(e)
            if any(err_msg in parsed_error for err_msg in LOCAL_NUDGE_ERROR_CODES):
                get_nudge_local_error(url, CONFIG, logger, True)
        except Exception as err:
            logger.debug(NUDGE_LOCAL_FUNC_EXCEPTION_ERROR.format(str(err)))
        raise e


def mod_pytest_update_current_test_var(item, when):
    global orig_pytest_update_current_test_var
    try:
        orig_pytest_update_current_test_var(item, when)
    except Exception as e:
        pass


def mod_pytest_bdd_runtest_makereport(item, call, rep):
    global orig_pytest_bdd_runtest_makereport
    global SESSION_DRIVERS
    name = ''
    try:
        if rep.when == 'call':
            SESSION_ID = threading.current_thread().bstackSessionId
            skipSessionName = item.config.getoption('skipSessionName')
            try:
                if (str(skipSessionName).lower() != 'true'):
                    name = str(rep.nodeid)
                    executor_string = browserstack_executor_helper('setSessionName', name, '', '', '', '')
                    os.environ['PYTEST_TEST_NAME'] = name
                    for driver in SESSION_DRIVERS:
                        if SESSION_ID == driver.session_id:
                            driver.execute_script(executor_string)
            except Exception as e:
                logger.debug('Error in setting sessionName for pytest-bdd session: {}'.format(str(e)))
            try:
                store_pytest_bdd_test_status(rep.outcome.lower())
                if rep.outcome.lower() != 'skipped':
                    status = 'failed' if rep.outcome.lower() == 'failed' else 'passed'
                    reason = ''
                    if status == 'failed':
                        reason = rep.longrepr.reprcrash.message
                        if (not threading.current_thread().bstackTestErrorMessages):
                            threading.current_thread().bstackTestErrorMessages = []
                        threading.current_thread().bstackTestErrorMessages.append(reason)
                    level = 'info' if status == 'passed' else 'error'
                    data = name + ' passed!' if status == 'passed' else name + ' failed! ' + reason
                    annotator_string = browserstack_executor_helper('annotate', '', '', '', level, data)
                    for driver in SESSION_DRIVERS:
                        if SESSION_ID == driver.session_id:
                            driver.execute_script(annotator_string)
            except Exception as e:
                logger.debug('Error in setting session context for pytest-bdd session: {}'.format(str(e)))
    except Exception as e:
        logger.debug('Error in getting state in pytest-bdd test status: {}'.format(str(e)))
    orig_pytest_bdd_runtest_makereport(item, call, rep)


notset = Notset()


def mod_pytest_get_option(self, name: str, default=notset, skip: bool = False):
    global orig_pytest_get_option
    if str(name).lower() == 'driver':
        return "BrowserStack"
    else:
        return orig_pytest_get_option(self, name, default, skip)


def mod_get_proxy_url(self):
    global CONFIG
    global orig_get_proxy_url
    # if http(s)Proxy is provided in CONFIG, use that
    # else use default selenium binding method which uses env variables, if set
    try:
        proxy = get_proxy_if_exists(CONFIG)
        if proxy:
            if proxy.endswith('.pac'):
                proxies = read_proxy_from_pac(proxy, get_hub_url())
                if len(proxies) > 0:
                    protocol, proxyVal = proxies.popitem()
                    if "://" in proxyVal:
                        return proxyVal
                    else:
                        return "http://" + proxyVal
            else:
                return proxy
    except Exception as e:
        logger.error("Error in setting proxy url : {}".format(str(e)))
    return orig_get_proxy_url(self)


def should_set_user_hub_proxy_for_selenium():
    return ('httpProxy' in CONFIG or 'httpsProxy' in CONFIG) and is_selenium_installed() and selenium_version_used() >= version.parse(
        MIN_PROXY_SUPPORTED_VERSION)

def mod_launch(self,
               executablePath=None,
               channel=None,
               args=None,
               ignoreDefaultArgs=None,
               handleSIGINT=None,
               handleSIGTERM=None,
               handleSIGHUP=None,
               timeout=None,
               env=None,
               headless=None,
               devtools=None,
               proxy=None,
               downloadsPath=None,
               slowMo=None,
               tracesDir=None,
               chromiumSandbox=None,
               firefoxUserPrefs=None
               ):
    global CONFIG
    global SESSION_NAME
    global PARALLELISE_VANILLA_PYTHON
    global FRAMEWORK_NAME

    # set the identifier cap for sdk used
    CONFIG['browserstackSDK'] = str(FRAMEWORK_NAME) + str(__version__)

    p_index = 0
    try:
        if PARALLELISE_VANILLA_PYTHON is True:
            p_index = int(os.environ.get('BROWSERSTACK_PLATFORM_INDEX'))
    except:
        p_index = 0

    CONFIG["isPlaywright"] = True
    caps_from_conf = get_caps(CONFIG, p_index)
    logger.debug(CONFIG_FILE_CONTENT.format(str(caps_from_conf)))

    if CONFIG.get('browserstackLocal'):
        update_caps_for_local(caps_from_conf, DEFAULT_LOCAL_ID)

    if 'platforms' in CONFIG and 'sessionName' in CONFIG['platforms'][p_index]:
        SESSION_NAME = CONFIG['platforms'][p_index]['sessionName']

    import urllib
    import json
    if 'turboScale' in CONFIG and str(CONFIG['turboScale']).lower() != 'false':
        playwright_hub_url = get_turboscale_playwright_url()
        cdpUrl = playwright_hub_url + urllib.parse.quote(json.dumps(caps_from_conf))
    else:
        cdpUrl = 'wss://cdp.browserstack.com/playwright?caps=' + urllib.parse.quote(json.dumps(caps_from_conf))
    browser = self.connect(cdpUrl)
    return browser

def patch_playwright():
    global SELENIUM_OR_PLAYWRIGHT_INSTALLED
    global FRAMEWORK_NAME
    # import Playwright
    try:
        from playwright._impl._browser_type import BrowserType
        from bstack_utils.helper import mod_playwright_connect
        # modify BrowserType methods
        if not is_bstack_automation():
            global orig_connect
            if not orig_connect:
                from bstack_utils.helper import set_playwright_orig_connect, set_global_playwright_framework_name
                orig_connect = set_playwright_orig_connect()
                set_global_playwright_framework_name(FRAMEWORK_NAME)
            BrowserType.connect = mod_playwright_connect
            return
        BrowserType.launch = mod_launch
        SELENIUM_OR_PLAYWRIGHT_INSTALLED = True
    except Exception as e:
        pass


def patch_driver():
    global CONFIG
    global IS_APP_AUTOMATE
    global HUB_URL
    global DEFAULT_LOCAL_ID
    global PARALLELISE_VANILLA_PYTHON
    global LOG_LEVEL

    CONFIG = json.loads(os.environ.get('BROWSERSTACK_CONFIG'))
    IS_APP_AUTOMATE = eval(os.environ.get('BROWSERSTACK_IS_APP_AUTOMATE'))
    HUB_URL = os.environ.get('BROWSERSTACK_HUB_URL')

    set_config_for_process(CONFIG, IS_APP_AUTOMATE)
    LOG_LEVEL = logger_utils.configure_logger(CONFIG, LOG_LEVEL)

    if cli.is_child_process():
        event_bus.invoke(Events.CONNECT, ConnectEvent())

        # TODO: temporary. this is supposed to arrive from the CLI-side in module_webdriver.py
        cli_context.platform_index = int(os.environ.get('BROWSERSTACK_PLATFORM_INDEX', '0'))
        # config = json.loads(os.environ.get("BROWSERSTACK_CONFIG", "{}"))
        # config_capabilities = get_caps(config, cli_context.platform_index) if isinstance(config, dict) else dict()
        # options = create_options_from_caps(cli.capabilities)
        # patch_playwright()
        cli.setup_playwright(cli_context.platform_index)

        cli.setup_selenium(get_hub_url(HUB_URL, CONFIG), cli_context.platform_index, create_options_from_caps)
        cli.setup_test_framework()

        logger.debug(f"CLI is active for platform_index={cli_context.platform_index}")
        return # skip all existing operations

    global orig_init
    global orig_quit
    global orig_test_status_init
    global orig_sel_lib_ff_prof
    global orig_queueitem_init
    global orig_create_command_for_execution
    global orig_close
    global orig_get
    global orig_get_proxy_url
    global orig_pytest_get_option
    global orig_pytest_update_current_test_var
    global orig_pytest_bdd_runtest_makereport

    # always import selenium webdriver (robot/pabot/python)
    try:
        from selenium import webdriver
        from selenium.webdriver.remote.webdriver import WebDriver
        # store original selenium webdriver methods
        orig_init = webdriver.Remote.__init__
        orig_quit = WebDriver.quit
        orig_close = WebDriver.close
        orig_get = WebDriver.get
    except Exception as e:
        pass

    # store proxy method if needed and supported
    if ('httpProxy' in CONFIG or 'httpsProxy' in CONFIG) and is_selenium_installed():
        if selenium_version_used() < version.parse(MIN_PROXY_SUPPORTED_VERSION):
            logger.error(PROXY_NOT_SUPPORTED.format(selenium_version_used()))
        else:
            try:
                from selenium.webdriver.remote.remote_connection import RemoteConnection
                if hasattr(RemoteConnection, '_get_proxy_url') and callable(getattr(RemoteConnection, '_get_proxy_url')):
                    # not obfuscating `_get_proxy_url` since the method has been removed >= 4.26.0, breaking version < 4.26.0
                    orig_get_proxy_url = RemoteConnection._get_proxy_url
                else:
                    from selenium.webdriver.remote.client_config import ClientConfig
                    orig_get_proxy_url = ClientConfig.get_proxy_url
            except Exception as e:
                logger.error(PROXY_SETUP_ERROR.format(str(e)))

    try:
        from _pytest.config import Config
        orig_pytest_get_option = Config.getoption
        from _pytest import runner
        orig_pytest_update_current_test_var = runner._update_current_test_var
    except Exception as e:
        logger.warn(e, IMPORT_ERROR_PYTEST)
    try:
        from pytest_bdd import reporting
        orig_pytest_bdd_runtest_makereport = reporting.runtest_makereport
    except Exception as e:
        logger.debug('Please install pytest-bdd to run pytest-bdd tests')

    DEFAULT_LOCAL_ID = CONFIG.get('browserStackLocalOptions', {}).get('localIdentifier')
    PARALLELISE_VANILLA_PYTHON = True
    mod_for_browserstack(PYTEST_PYTHON)


if (is_browserstack_session()):
    patch_driver()


@error_handler(class_method=False)
def hook_handler(hook_name, event, hook_result=None):
    if hook_name not in ['setup_function', 'teardown_function', 'setup_module', 'teardown_module', 'setup_class', 'teardown_class', 'setup_method', 'teardown_method']:
        return
    node = store['current_test_item']
    if hook_name in ['setup_module', 'teardown_module']:
        node = store['current_module_item']
    elif hook_name in ['setup_class', 'teardown_class']:
        node = store['current_class_item']
    hook_type = hook_type_from_hook_name(hook_name)
    if event == 'before':
        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState[hook_type], TestHookState.PRE, node, hook_name)
            return
        uuid = uuid4().__str__()
        hook_meta_data = {
            'uuid': uuid,
            'started_at': current_time(),
            'type': 'hook',
            'hook_type': hook_type,
            'hook_name': hook_name
        }
        store['current_hook_uuid'].append(uuid)
        node_id = node.nodeid
        if hook_type == 'BEFORE_EACH':
            if not _tests.get(node_id, None):
                _tests[node_id] = {'hooks': []}
            _tests[node_id]['hooks'].append(hook_meta_data['uuid'])
        _tests[node_id + '-' + hook_name] = hook_meta_data
        send_hook_run_event(node, hook_meta_data, 'HookRunStarted')
    elif event == 'after':
        if cli.is_running():
            cli.test_framework.track_event(cli_context, TestFrameworkState[hook_type], TestHookState.POST, node, None, hook_result)
            return
        hook_id = node.nodeid + '-' + hook_name
        _tests[hook_id]['finished_at'] = current_time()
        remove_current_hook(_tests[hook_id]['uuid'])
        send_hook_run_event(node, _tests[hook_id], 'HookRunFinished', custom_result=hook_result)


def set_framework_for_o11y():
    global FRAMEWORK
    if is_pytest_bdd():
        FRAMEWORK = 'pytest-bdd'
    else:
        FRAMEWORK = 'pytest'

def pytest_collection_modifyitems(session, config, items):
    """
    Filters collected pytest items based on orchestrated selectors from orchestration server.
    """
    import os
    orchestrated_selectors_json = os.environ.get('BROWSERSTACK_ORCHESTRATED_SELECTORS')
    logger.info("[pytest_collection_modifyitems] Orchestrated selectors json received: {}".format(orchestrated_selectors_json))
    if not orchestrated_selectors_json:
        # No orchestration, run all tests
        return
    try:
        orchestrated_selectors = json.loads(orchestrated_selectors_json)
        if not isinstance(orchestrated_selectors, (list, set)) or not orchestrated_selectors:
            # Malformed or empty selectors, run all
            return
    except Exception as e:
        # Malformed JSON, log and run all
        logger.debug(f"Could not parse BROWSERSTACK_ORCHESTRATED_SELECTORS: {e}")
        return

    selected = []
    deselected = []
    logger.info("[pytest_collection_modifyitems] Orchestrated selectors received: {}".format(orchestrated_selectors))
    # Normalize selectors for matching
    normalized_selectors = set()
    for selector in orchestrated_selectors:
        if not selector or not isinstance(selector, str):
            continue
        normalized_selectors.add(selector)
        # Optionally, add logic to expand file names to all nodeids in those files

    for item in items:
        nodeid = getattr(item, 'nodeid', None)
        if not nodeid:
            deselected.append(item)
            continue
        # Match nodeid exactly, or by substring for partial selectors
        if (
            nodeid in normalized_selectors or
            any(sel in nodeid for sel in normalized_selectors)
        ):
            selected.append(item)
        else:
            deselected.append(item)

    if deselected:
        logger.info("[pytest_collection_modifyitems] Deselected tests: {}".format(deselected))
        config.hook.pytest_deselected(items=deselected)
        items[:] = selected


@TestHubHandler.need_th
def patch_class():
    set_framework_for_o11y()
    if cli.is_running():
        try:
            HooksPatch(hook_handler)
        except Exception as e:
            logger.debug("Exception in hooks patch: {}".format(e))
        return

    if is_selenium_installed():
        global_config = Config.get_instance()
        '''
            For ppp = 1, mod_execute gets used for a11y commands-wrapping
            For ppp > 1, mod_execute does not run because it is patched in a different process id
            Thus we need to use SeleniumPatch(selenium_handler) for ppp > 1
        '''
        if global_config.get_property('bstack_mod_called'):
            if CONFIG.get('parallelsPerPlatform') is not None and int(CONFIG['parallelsPerPlatform']) > 1:
                SeleniumPatch(selenium_handler)
            return
        SeleniumPatch(selenium_handler)
    try:
        HooksPatch(hook_handler)
    except Exception as e:
        logger.debug("Exception in hooks patch: {}".format(e))


patch_class()
